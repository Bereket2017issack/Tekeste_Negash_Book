{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyDbrrMJ21ffNI0IANfhGIM2xDPbkUEfN90\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would the long-term societal impact of widespread adoption of highly personalized, AI-driven education systems differ depending on the pre-existing levels of socioeconomic inequality within a society, and what ethical considerations should guide the design and implementation of such systems to mitigate potential negative consequences?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gemini API Key\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "gemini_api_key = \"AIzaSyDbrrMJ21ffNI0IANfhGIM2xDPbkUEfN90\"\n",
    "#configure your APY key\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "\n",
    "# Create a model object\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Generate content\n",
    "\n",
    "question = model.generate_content(messages[0][\"content\"])\n",
    "#question = response.choices[0].message.content\n",
    "# Print the response    \n",
    "print(question.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai = OpenAI()\n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     messages=messages,\n",
    "# )\n",
    "# question = response.choices[0].message.content\n",
    "# print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question.text}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Ethical Implications of AI-Driven Societal Crisis Prediction and Mitigation\n",
       "\n",
       "The use of advanced AI to predict and preemptively mitigate societal crises presents a complex ethical landscape, fraught with both immense potential benefits and significant risks.  While the prospect of preventing catastrophes like famines, pandemics, or even social unrest is alluring, the methods employed and potential consequences necessitate careful consideration.\n",
       "\n",
       "**Potential Benefits:**\n",
       "\n",
       "* **Proactive Crisis Management:**  AI could analyze vast datasets (economic indicators, social media sentiment, climate data, etc.) to identify early warning signs of impending crises, enabling timely interventions. This proactive approach could save lives, reduce suffering, and minimize economic damage.\n",
       "* **Resource Allocation Optimization:** By predicting the scale and location of crises, resources (financial aid, medical supplies, emergency services) can be allocated more effectively, maximizing impact and minimizing waste.\n",
       "* **Improved Policymaking:** Data-driven insights from AI can inform policy decisions, leading to more evidence-based and effective strategies for crisis prevention and response.\n",
       "* **Early Intervention for Vulnerable Populations:** AI could identify individuals or groups at heightened risk, allowing for targeted interventions to enhance resilience and prevent disproportionate impact.\n",
       "\n",
       "\n",
       "**Potential Unintended Consequences and Abuses of Power:**\n",
       "\n",
       "* **Bias and Discrimination:** AI models are trained on data, which often reflects existing societal biases.  This can lead to biased predictions, disproportionately affecting marginalized communities and exacerbating existing inequalities. For example, an AI predicting crime might unfairly target specific demographics.\n",
       "* **Erosion of Privacy and Civil Liberties:**  The data required for accurate predictions often includes sensitive personal information.  Collecting, storing, and analyzing this data raises significant privacy concerns, potentially leading to surveillance and restrictions on freedom.\n",
       "* **False Positives and Negative Consequences of Preemptive Actions:** Incorrect predictions could lead to unnecessary and potentially harmful interventions. For example, preemptive lockdowns based on flawed predictions could damage economies and infringe on individual freedoms.\n",
       "* **Concentration of Power:**  The ability to predict and manage societal crises could concentrate significant power in the hands of those controlling the AI systems and the data they utilize. This could lead to authoritarianism and a lack of accountability.\n",
       "* **Self-Fulfilling Prophecies:**  Predictions themselves can influence behavior, potentially creating the very crisis they predicted.  For example, predicting widespread panic could trigger that very panic.\n",
       "* **Lack of Transparency and Explainability:** Many advanced AI models (e.g., deep learning) are \"black boxes,\" making it difficult to understand how they arrive at their predictions.  This lack of transparency hinders accountability and trust.\n",
       "\n",
       "\n",
       "**Acknowledging Limitations and Human Agency:**\n",
       "\n",
       "AI predictive models are inherently limited. They cannot account for unpredictable events, human agency, or complex social dynamics fully.  Over-reliance on AI predictions can lead to neglecting crucial human factors and expertise. Maintaining human oversight and control over the decision-making process is paramount.  Ethical frameworks must ensure that AI serves as a tool to *support* human judgment, not replace it.\n",
       "\n",
       "**Ethical Considerations and Recommendations:**\n",
       "\n",
       "* **Data Governance and Privacy Protection:**  Robust data governance frameworks are crucial, ensuring data security, privacy, and responsible data collection practices.\n",
       "* **Algorithmic Auditing and Bias Mitigation:** Regular auditing of AI models is essential to detect and mitigate bias. Techniques like fairness-aware machine learning should be employed.\n",
       "* **Transparency and Explainability:**  Efforts should be made to develop more explainable AI models, allowing for better understanding and accountability.\n",
       "* **Human Oversight and Accountability:**  Human experts should retain ultimate control over decisions, ensuring ethical considerations are prioritized.  Mechanisms for accountability and redress should be established.\n",
       "* **Public Engagement and Deliberation:**  Open and inclusive discussions are needed to address the ethical and societal implications of AI-driven crisis prediction and mitigation.\n",
       "\n",
       "\n",
       "In conclusion, while the potential benefits of using AI to mitigate societal crises are substantial, the ethical challenges are equally significant. A responsible approach requires a careful balancing act between leveraging the potential of AI and safeguarding against its risks, prioritizing human agency, transparency, and accountability throughout the process.  Robust ethical frameworks, regulations, and ongoing public discourse are essential to ensure that this powerful technology is used for the common good and not to the detriment of individuals or society as a whole.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gemini API Key\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "gemini_api_key = \"AIzaSyDbrrMJ21ffNI0IANfhGIM2xDPbkUEfN90\"\n",
    "#configure your APY key\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "\n",
    "# Create a model object\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "model_name = \"gemini-1.5-flash\"\n",
    "\n",
    "# Generate content\n",
    "\n",
    "answer = model.generate_content(messages[0][\"content\"])\n",
    "#question = response.choices[0].message.content\n",
    "# Print the response    \n",
    "\n",
    "display(Markdown(answer.text))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer.text)\n",
    "#print(response.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The API we know well\n",
    "\n",
    "# model_name = \"gpt-4o-mini\"\n",
    "\n",
    "# response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## The Ethical Tightrope: AI, Societal Crises, and the Future of Preemptive Action\n",
       "\n",
       "Using advanced AI to predict and preemptively mitigate societal crises presents a tantalizing prospect – a future where we can avoid disasters before they strike. However, navigating this potential requires careful consideration of the complex ethical implications, balancing the benefits against the potential for abuse and unintended consequences.\n",
       "\n",
       "**Potential Benefits:**\n",
       "\n",
       "* **Early Warning Systems:** AI can analyze vast datasets (social media trends, economic indicators, environmental data) to identify patterns indicative of impending crises like pandemics, economic crashes, social unrest, or natural disasters. This early warning allows for proactive intervention, potentially saving lives and minimizing damage.\n",
       "* **Resource Allocation Optimization:**  AI can optimize the deployment of resources based on predicted needs during a crisis. For example, predicting hospital bed shortages and redistributing resources accordingly, or directing aid to areas most vulnerable after a natural disaster.\n",
       "* **Informed Policy Making:** AI-driven insights can inform policy decisions, enabling governments to address underlying issues that contribute to societal instability, such as poverty, inequality, or environmental degradation.\n",
       "* **Improved Risk Assessment:** AI can assess risks more comprehensively than traditional methods, factoring in a wider range of variables and identifying potential vulnerabilities that might otherwise be overlooked.\n",
       "\n",
       "**Potential Downsides and Ethical Concerns:**\n",
       "\n",
       "* **Bias and Discrimination:** AI models are trained on data, and if that data reflects existing societal biases (e.g., racial profiling in policing), the AI will perpetuate and even amplify those biases. This could lead to disproportionate targeting of certain communities and exacerbate existing inequalities.\n",
       "* **Privacy Violations:**  Collecting and analyzing vast amounts of data to predict societal crises raises serious privacy concerns. Surveillance and data collection can erode trust in institutions and create a chilling effect on free speech and assembly.\n",
       "* **Abuse of Power and Authoritarianism:** The ability to predict and preempt crises could be misused by governments to suppress dissent, control populations, and consolidate power.  \"Preemptive\" actions could be justified based on AI predictions, even if those predictions are inaccurate or manipulated.\n",
       "* **Self-Fulfilling Prophecies:**  AI predictions, even if accurate, can create self-fulfilling prophecies.  For instance, predicting a stock market crash could trigger panic selling and ultimately lead to the crash. Similarly, identifying certain groups as \"high-risk\" for crime could lead to increased surveillance and policing, further marginalizing those communities.\n",
       "* **Lack of Transparency and Accountability:**  Complex AI models are often \"black boxes,\" making it difficult to understand how they arrive at their predictions. This lack of transparency makes it challenging to hold decision-makers accountable for actions based on AI-driven insights.\n",
       "* **Erosion of Human Agency and Due Process:** Relying too heavily on AI predictions can lead to a dismissal of human judgment and a violation of due process.  Individuals could be subjected to preventative measures based solely on an AI prediction, without adequate opportunity to challenge the decision.\n",
       "* **Over-Reliance and Complacency:**  Trusting AI predictions too much can lead to complacency and a neglect of other important sources of information and analysis. This could create blind spots and make societies more vulnerable to unexpected events.\n",
       "* **Ethical Dilemmas of Intervention:** When do potential benefits justify potentially intrusive interventions? Balancing public safety with individual rights is a fundamental ethical challenge. Determining the appropriate level of intervention based on AI predictions requires careful consideration and democratic oversight.\n",
       "\n",
       "**Limitations of Predictive Models and Importance of Human Agency:**\n",
       "\n",
       "It is crucial to recognize that AI predictive models are inherently limited. They are based on historical data and statistical probabilities, which may not accurately reflect future events. Unforeseen circumstances, human agency, and emergent phenomena can significantly alter the course of events.\n",
       "\n",
       "Therefore, AI should be used as a tool to inform decision-making, not to replace human judgment. Human expertise, ethical considerations, and democratic processes are essential to ensuring that AI is used responsibly and for the benefit of society.\n",
       "\n",
       "**Key Considerations for Ethical Implementation:**\n",
       "\n",
       "* **Data Privacy and Security:**  Implement robust data privacy safeguards to protect sensitive information and prevent misuse.\n",
       "* **Transparency and Explainability:** Strive for greater transparency in AI models, making it easier to understand how they work and how they arrive at their predictions.\n",
       "* **Bias Mitigation:**  Actively identify and mitigate biases in data and algorithms to ensure fairness and equity.\n",
       "* **Human Oversight and Accountability:**  Establish clear lines of accountability for decisions made based on AI predictions.  Require human oversight to ensure that AI is used ethically and responsibly.\n",
       "* **Robust Testing and Validation:**  Thoroughly test and validate AI models to ensure their accuracy and reliability.\n",
       "* **Democratic Governance and Public Engagement:**  Engage the public in discussions about the ethical implications of using AI to predict and prevent societal crises. Establish democratic governance mechanisms to ensure that AI is used in a way that reflects societal values.\n",
       "* **Focus on Addressing Root Causes:**  Use AI insights to identify and address the root causes of societal crises, rather than simply reacting to symptoms.\n",
       "* **Continuous Evaluation and Adaptation:** Regularly evaluate the effectiveness and ethical implications of AI-driven interventions and adapt them as needed.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "Using AI to predict and preempt societal crises offers the potential to improve human lives and create a more resilient society. However, realizing this potential requires careful consideration of the ethical implications and a commitment to responsible development and deployment.  By prioritizing fairness, transparency, accountability, and human agency, we can harness the power of AI for good, while mitigating the risks of unintended consequences and abuse of power.  The future we create will depend on our ability to navigate this complex ethical terrain with wisdom and foresight.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=GOOGLE_API_KEY, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
